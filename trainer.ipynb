{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0of3NTyl90I",
        "outputId": "a39a3cd4-5ba8-496a-f51c-9e634ccdcd34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "doN1Kg_kkwhb",
        "outputId": "b88fe174-f55d-44fc-e82d-0113ab7df3da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ".:\n",
            "total 8\n",
            "drwx------ 6 root root 4096 Nov 28 23:51 drive\n",
            "drwxr-xr-x 1 root root 4096 Nov 20 14:30 sample_data\n",
            "\n",
            "/content/drive/MyDrive/:\n",
            "total 23\n",
            "-rw------- 1 root root 10589 Jun  2 23:59  blocks.py\n",
            "drwx------ 2 root root  4096 Nov 18 09:25 'Chrome에서 저장됨'\n",
            "drwx------ 2 root root  4096 Nov 15 12:20 'Colab Notebooks'\n",
            "-rw------- 1 root root   174 Nov 26 21:37  urop_test_result.gsheet\n",
            "drwx------ 2 root root  4096 Mar 14  2025  인공지능학부\n"
          ]
        }
      ],
      "source": [
        "!ls -l /content/drive/MyDrive/ .\n",
        "# gdrive check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYe5DgBdlp8J"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.getcwd()\n",
        "# gdrive check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBxbKMw3G8eZ"
      },
      "outputs": [],
      "source": [
        "!cp /content/drive/MyDrive/blocks.py ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXg6Xxd9E96s"
      },
      "outputs": [],
      "source": [
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "# cuda error catch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHAQO2067WsV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms, models\n",
        "from torchvision.transforms import v2\n",
        "from blocks import resnet34_peft, resnet50_peft, AdapterLayer, LoRALayer\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import random\n",
        "\n",
        "def train(model, train_dataloader, valid_dataloader, optim, loss_fn, num_epoch, device):\n",
        "    train_epoch_losses = []\n",
        "    eval_epoch_losses = []\n",
        "\n",
        "    for epoch in range((num_epoch)):\n",
        "        model.train()\n",
        "        step_loss = []\n",
        "        for data in tqdm(train_dataloader, desc=\"Training\"):\n",
        "            inputs, labels = data\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optim.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            train_loss = loss_fn(outputs, labels)\n",
        "            train_loss.backward()\n",
        "            optim.step()\n",
        "            step_loss.append(train_loss.item())\n",
        "        train_epoch_losses.append(sum(step_loss) / len(step_loss))\n",
        "\n",
        "        model.eval()\n",
        "        total = 0\n",
        "        correct = 0\n",
        "        accuracy = []\n",
        "        with torch.no_grad():\n",
        "            step_loss = []\n",
        "            for data in tqdm(valid_dataloader, desc=\"Evaluation\"):\n",
        "                inputs, labels = data\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "                test_loss = loss_fn(outputs, labels)\n",
        "                accuracy.append(100 * correct/total)\n",
        "                step_loss.append(test_loss.item())\n",
        "            eval_epoch_losses.append(sum(step_loss) / len(step_loss))\n",
        "        print('Epoch: %d/%d, Train loss: %.6f, Test loss: %.6f, Accuracy: %.2f' %(epoch+1, num_epoch, train_loss.item(), test_loss, 100*correct/total))\n",
        "\n",
        "        plt.plot(train_epoch_losses, label='train_loss')\n",
        "        plt.plot(eval_epoch_losses, label='eval_loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "def freeze_model(model):\n",
        "    model.requires_grad_(False)\n",
        "    model.fc.requires_grad_(True)\n",
        "    for name, module in model.named_modules():\n",
        "        if isinstance(module, AdapterLayer):\n",
        "            module.requires_grad_(True)\n",
        "    for name, param in model.named_parameters():\n",
        "        if 'lora_' in name:\n",
        "            param.requires_grad = True\n",
        "    n_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    n_total_params = sum(p.numel() for p in model.parameters())\n",
        "    print(\n",
        "        f\"Trainable parameters: {n_trainable_params:,d} / {n_total_params} \"\n",
        "        f\"({100 * n_trainable_params / n_total_params:.2f}%)\"\n",
        "    )\n",
        "\n",
        "\n",
        "def main():\n",
        "    seed = 42\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    print(device)\n",
        "    model = resnet50_peft(lora_r=0, adapter_r=2) #### test ####\n",
        "    transform = v2.Compose([\n",
        "        v2.ToTensor(),\n",
        "        v2.Normalize([0.5487, 0.5313, 0.5050], [0.2497, 0.2467, 0.2483]),\n",
        "        v2.Resize((224, 224)),\n",
        "        v2.RGB(),\n",
        "    ])\n",
        "    dataset = datasets.Caltech256('/content/drive/MyDrive/Colab Notebooks/data', transform=transform, )\n",
        "    train_dataset, valid_dataset = torch.utils.data.random_split(\n",
        "        dataset,\n",
        "        [0.9, 0.1],\n",
        "        torch.Generator().manual_seed(42)\n",
        "    )\n",
        "\n",
        "    # Hyperparameters\n",
        "    num_classes = 257 # check it\n",
        "    batch_size = 32\n",
        "    epochs = 20\n",
        "    learning_rate = 0.001\n",
        "\n",
        "    # model\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    model = model.to(device)\n",
        "    freeze_model(model)\n",
        "\n",
        "    # with regularization\n",
        "    optimizer = optim.Adam(\n",
        "        filter(lambda p: p.requires_grad, model.parameters()),\n",
        "        lr=learning_rate, weight_decay=0.01\n",
        "    )\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size,\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    valid_loader = torch.utils.data.DataLoader(\n",
        "        valid_dataset,\n",
        "        batch_size=1,\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    train(model, train_loader, valid_loader, optimizer, loss_fn, epochs, device)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYgMIQN6MveC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
